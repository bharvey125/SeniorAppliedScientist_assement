{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7964433b-7fb1-47bd-a1de-f0ccbb61b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7918ce83-7007-4175-b056-62b2169e2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = r\"D:/Database/Trans_ontime_perf.csv\"\n",
    "\n",
    "data = pd.read_csv(in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2e2411-94a1-4472-9ef8-9dfe305a1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "\n",
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f'Function {func.__name__}{args} {kwargs} Took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return timeit_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7327be3a-f452-41af-8f71-fcaa1691c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_download(url_name,file_name,out_path):\n",
    "    #lazy import\n",
    "    from zipfile import ZipFile\n",
    "    from urllib.request import urlopen   \n",
    "    import os\n",
    "    URL = url_name\n",
    "    file_name = file_name\n",
    "  \n",
    "    url = urlopen(URL)\n",
    "    output = open(file_name+'.zip', 'wb')    # note the flag:  \"wb\"\n",
    "\n",
    "    output.write(url.read())\n",
    "    output.close()\n",
    " \n",
    "    # read the zip file as a pandas dataframe\n",
    "    df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files     \n",
    "    # df.to_csv(out_path+file_name)\n",
    "    # if keeping on disk the zip file is not wanted, then:\n",
    " \n",
    "    os.remove(file_name+'.zip')\n",
    "    df.to_csv(out_path+file_name+'.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "490d71e6-6a72-4c7d-9553-5c0405e784e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing file: on_time_performance_2021_09:   0%|                                             | 0/26 [00:00<?, ?it/s]C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3670572368.py:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files\n",
      "Processing file: on_time_performance_2021_11:   8%|██▊                                  | 2/26 [01:29<17:49, 44.56s/it]C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3670572368.py:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files\n",
      "Processing file: on_time_performance_2022_06:  35%|████████████▊                        | 9/26 [06:41<12:21, 43.63s/it]C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3670572368.py:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files\n",
      "Processing file: on_time_performance_2022_07:  38%|█████████████▊                      | 10/26 [07:25<11:40, 43.80s/it]C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3670572368.py:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files\n",
      "Processing file: on_time_performance_2023_03:  69%|████████████████████████▉           | 18/26 [13:56<06:57, 52.24s/it]C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3670572368.py:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files\n",
      "Processing file: on_time_performance_2023_05:  77%|███████████████████████████▋        | 20/26 [15:37<05:06, 51.15s/it]C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3670572368.py:16: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name+'.zip')   # pandas version 0.18.1 takes zip files\n",
      "Processing file: on_time_performance_2023_10: 100%|████████████████████████████████████| 26/26 [20:24<00:00, 47.09s/it]\n"
     ]
    }
   ],
   "source": [
    "urls = data.URL\n",
    "pbar = tqdm.tqdm(urls[2:])\n",
    "out_path = r\"D:/Database/on_time_data/\"\n",
    "for url in pbar:\n",
    "    file_name = url.split('/')[-1].split('.')[0]\n",
    "    pbar.set_description('Processing file: %s' %file_name)\n",
    "    data_download(url, file_name,out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2fc04-0904-49c7-9c52-447d73fbbc14",
   "metadata": {},
   "source": [
    "# above this cell is downloading data\n",
    "# below is transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b397b679-1249-4ff4-89a1-e53e2cbb011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_path = r'D:\\Database\\winnipeg 2021-01-01 to 2023-11-30.csv'\n",
    "traffic_path = r'D:\\Database\\Permanent_Count_Station_Traffic_Counts.csv'\n",
    "bus_use_path = r'D:\\Database\\Estimated_Daily_Passenger_Activity.csv'\n",
    "oct_data_path = r'D:\\Database\\on_time_data\\on_time_performance_2023_10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e31e0c8-a4e4-4f7f-bf4b-6efe6c1aa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(weather_path)\n",
    "traffic = pd.read_csv(traffic_path)\n",
    "bus_use = pd.read_csv(bus_use_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f16b6e86-37e0-41f7-a2cf-5b79ba360120",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_data2 = pd.read_csv(oct_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a014a9-f67e-48df-a61a-9d3df292a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic.Timestamp = pd.to_datetime(traffic.Timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be6e48a-05a1-41ef-bb56-ee2bd35757b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = traffic.sort_values(['Site','Timestamp']).reset_index(drop = True)\n",
    "traffic2 = traffic.loc[:,['Timestamp','Site','Right','Left','Total','Latitude','Longitude']]\n",
    "traffic2['date_key']= traffic2.Timestamp.dt.floor('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237e4d93-6888-4cae-8d03-644b735dac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic3 = traffic2.groupby(['Site','date_key']).mean()\n",
    "traffic3 = traffic3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817eaadc-b02d-46df-a959-b3748b009129",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2 = weather.loc[:,['windspeed','precip','temp','datetime', 'preciptype', 'snow', 'snowdepth']]\n",
    "weather2['datetime'] = pd.to_datetime(weather2.datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c7e42a5-1193-4117-94ae-9eae165ea93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trans(_data,w_data,t_data):\n",
    "    _data['Scheduled Time'] = pd.to_datetime(_data['Scheduled Time'])\n",
    "    _data['date_key'] = _data['Scheduled Time'].dt.floor('h')\n",
    "    _data = _data.merge(w_data,how = 'left',left_on = 'date_key', right_on = 'datetime')\n",
    "    _data['Longitude'] = _data.Location.apply(lambda x:float(x.split(' ')[1].split('(')[1]))\n",
    "    _data['Latitude'] = _data.Location.apply(lambda x:float(x.split(' ')[2].split(')')[0]))\n",
    "    \n",
    "    area_map = t_data.loc[:,['Site','Latitude','Longitude']].groupby(['Site']).mean().reset_index().reset_index()\n",
    "    temp = cdist(_data.loc[:,['Longitude','Latitude']],area_map [[\"Longitude\",\"Latitude\"]])\n",
    "    _data['area_index'] = np.argmin(temp,axis =1)\n",
    "    \n",
    "    # for i,row in tqdm.tqdm(enumerate(temp)):\n",
    "    #     _data.iloc[i,-1] = np.argmin(row)\n",
    "    \n",
    "    t_data = t_data.merge(area_map.loc[:,['index','Site']],how='left',left_on = 'Site',right_on = 'Site')\n",
    "    t_data.date_key = pd.to_datetime(t_data.date_key).dt.tz_localize(None)\n",
    "  \n",
    "    _data = _data.merge(t_data,how = 'left',left_on=['area_index','date_key'], right_on = ['index','date_key'])\n",
    "    _data = _data.drop(['Unnamed: 0','Row ID','Timestamp','index', 'temp','Location'],axis = 1)\n",
    "    _data.preciptype = _data.preciptype.fillna('None')\n",
    "    _data = _data.fillna(0)\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb9824f5-0177-4907-aa09-097ec9791ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = load_trans(oct_data2, weather2,traffic3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8636f4e-50da-4d48-a92a-8fad3232a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(r'D:\\Database\\on_time_data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3ef7bbe6-df70-47bd-9999-cad09f575bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v2_on_time_performance_2023_08.csv',\n",
       " 'v2_on_time_performance_2023_09.csv',\n",
       " 'v2_on_time_performance_2023_10.csv']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f290dd82-71f0-46b4-95ac-8d203b7b93c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imported file: on_time_performance_2023_10.csv - Starting Processing: 100%|██████████████| 3/3 [04:56<00:00, 98.85s/it]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm.tqdm(file_list[-3:])\n",
    "for name in pbar:\n",
    "    file_name = r'D:/Database/on_time_data/' + name\n",
    "    raw_data = pd.read_csv(file_name)\n",
    "    pbar.set_description('imported file: %s - Starting Processing'  %name)\n",
    "    out_file = load_trans(raw_data, weather2,traffic3)\n",
    "    out_file.to_csv( r'D:/Database/on_time_data/v2_' + name)\n",
    "    del out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3483fa03-4578-49ae-bcb0-2184a0cef505",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Stop Number','Route Number','Route Name','Route Destination'\n",
    ",'Day Type'\n",
    ",'Scheduled Time'\t\n",
    ",'Deviation'\n",
    ",'date_key'\n",
    ",'windspeed'\n",
    ",'precip'\n",
    ",'preciptype'\n",
    ",'Site'\n",
    ",'Right'\n",
    ",'Left'\n",
    ",'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310af62-de02-4553-915b-18564be659f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc2ed3e4-03b6-4601-b5d4-f77fe00e9031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\3487216635.py:1: DtypeWarning: Columns (2,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  target_data = pd.read_csv(r'D:/Database/on_time_data/'+file_list[-3])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c4646acb-113f-47ce-86e2-7618b70bd2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94850406-f781-4bbb-867a-beaf9ca1648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging in area shapes file\n",
    "\n",
    "area_shape = gpd.read_file(r'D:\\Database\\Neighbourhood.geojson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7699b064-3212-4a14-b3eb-395c52bc11ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>759</td>\n",
       "      <td>Rossmere-B</td>\n",
       "      <td>MULTIPOLYGON (((-97.08240 49.92037, -97.08139 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>MULTIPOLYGON (((-97.32647 49.87836, -97.32679 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1474</td>\n",
       "      <td>Armstrong Point</td>\n",
       "      <td>MULTIPOLYGON (((-97.15236 49.87560, -97.15310 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>Burrows-Keewatin</td>\n",
       "      <td>MULTIPOLYGON (((-97.18195 49.92749, -97.18201 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>Melrose</td>\n",
       "      <td>MULTIPOLYGON (((-97.02536 49.89362, -97.02536 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id              name                                           geometry\n",
       "0   759        Rossmere-B  MULTIPOLYGON (((-97.08240 49.92037, -97.08139 ...\n",
       "1    87          Glendale  MULTIPOLYGON (((-97.32647 49.87836, -97.32679 ...\n",
       "2  1474   Armstrong Point  MULTIPOLYGON (((-97.15236 49.87560, -97.15310 ...\n",
       "3    95  Burrows-Keewatin  MULTIPOLYGON (((-97.18195 49.92749, -97.18201 ...\n",
       "4   158           Melrose  MULTIPOLYGON (((-97.02536 49.89362, -97.02536 ..."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_shape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e2a549aa-eaa0-414e-ab4c-345348f29328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Database/on_time_data/v2_on_time_performance_2023_08.csv'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_file = r'D:/Database/on_time_data/'+file_list[-3]\n",
    "target_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b108e72a-2c23-4786-aef6-6bfeb3a86ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blhar\\AppData\\Local\\Temp\\ipykernel_4604\\427127472.py:1: DtypeWarning: Columns (2,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  target_data = pd.read_csv(target_file)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 400. MiB for an array with shape (11, 4761400) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m target_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m target_data\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# target_data = target_data.drop(['Unnamed: 0'],axis = 1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# target_data = gpd.GeoDataFrame(target_data,\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#                                 geometry=gpd.points_from_xy(target_data.Longitude_x,target_data.Latitude_x\t),crs=\"EPSG:4326\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1765\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1763\u001b[0m         new_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index)\n\u001b[1;32m-> 1765\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2091\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2089\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2091\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1750\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1750\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1751\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2217\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2215\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2217\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2220\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kedro_project\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2249\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2248\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2249\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2250\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2252\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 400. MiB for an array with shape (11, 4761400) and data type object"
     ]
    }
   ],
   "source": [
    "\n",
    "target_data = pd.read_csv(target_file)\n",
    "target_data.shape\n",
    "# target_data = target_data.drop(['Unnamed: 0'],axis = 1)\n",
    "# target_data = gpd.GeoDataFrame(target_data,\n",
    "#                                 geometry=gpd.points_from_xy(target_data.Longitude_x,target_data.Latitude_x\t),crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f0abcd7-1f64-4ece-a043-66621117e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.sjoin(target_data,area_shape,how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d84c21a-9064-4c17-9c74-bb8a350f0a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500909, 27)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6819f7fc-b4a2-4564-9e2a-6d18b70f03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d287c4-0487-4d07-ab61-cd438eb5e6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
